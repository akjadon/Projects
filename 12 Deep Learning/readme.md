## Reference
* [CS231n](http://cs231n.github.io/neural-networks-1/)
* [DeepAI](https://deepai.org)
* [Go Deep](http://www.godeep.ml)
* [Tensorflow](https://www.tensorflow.org/tutorials)
* [ConvNetJS](https://cs.stanford.edu/people/karpathy/convnetjs/index.html)
* [Metacademy](https://metacademy.org/graphs/concepts/weight_decay_neural_networks#focus=backpropagation&mode=learn)
* [deepschool.io](https://github.com/RyanSydney/deepschool.io)
* [deeplearning.ai](https://www.deeplearning.ai)
* [Easy Tensorflow](http://www.easy-tensorflow.com)
* [Capsule Networks](https://medium.com/ai³-theory-practice-business/understanding-hintons-capsule-networks-part-i-intuition-b4b559d1159b)
* [The Neural Network Zoo](http://www.asimovinstitute.org/neural-network-zoo/)
* [What Are Hidden Layers?](https://medium.com/fintechexplained/what-are-hidden-layers-4f54f7328263)
* [A Glossary of Deep Learning](https://medium.com/deeper-learning/a-glossary-of-deep-learning-9cb6292e087e)
* [Neural Networks Demystified](https://www.youtube.com/playlist?list=PLiaHhY2iBX9hdHaRr6b7XevZtgZRa1PoU)
* [Moving from Keras to Pytorch](https://towardsdatascience.com/moving-from-keras-to-pytorch-f0d4fff4ce79)
* [Introduction to Neural Networks](https://towardsdatascience.com/simple-introduction-to-neural-networks-ac1d7c3d7a2c)
* [China’s Big AI Advantage: Humans](https://www.youtube.com/watch?v=tMZgRTQ-hv4)
* [Neural Networks Bias And Weights](https://medium.com/fintechexplained/neural-networks-bias-and-weights-10b53e6285da)
* [Deep Learning: A Critical Appraisal](https://arxiv.org/ftp/arxiv/papers/1801/1801.00631.pdf)
* [Practical Deep Learning for Coders](https://course.fast.ai)
* [An Introduction to Transfer Learning](https://medium.com/georgian-impact-blog/transfer-learning-part-1-ed0c174ad6e7)
* [The Building Blocks of Interpretability](https://distill.pub/2018/building-blocks/)
* [10 New Things I Learnt from fast.ai v3](https://towardsdatascience.com/10-new-things-i-learnt-from-fast-ai-v3-4d79c1f07e33)
* [Intermediate Topics in Neural Networks](https://towardsdatascience.com/comprehensive-introduction-to-neural-network-architecture-c08c6d8e5d98)
* [Understanding Tensor Processing Units](https://medium.com/sciforce/understanding-tensor-processing-units-10ff41f50e78)
* [A Step by Step Backpropagation Example](https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/)
* [Reinforcement Learning With Python — AI](https://medium.com/@rinu.gour123/reinforcement-learning-with-python-ai-92951084a9e6)
* [List of Deep Learning and NLP Resources](http://cs-www.cs.yale.edu/homes/radev/dlnlp2017.pdf)
* [Neural Network Activation Function Types](https://medium.com/fintechexplained/neural-network-activation-function-types-a85963035196)
* [An introduction to Reinforcement Learning](https://medium.freecodecamp.org/an-introduction-to-reinforcement-learning-4339519de419)
* [Deep Dive into Math Behind Deep Networks](https://towardsdatascience.com/https-medium-com-piotr-skalski92-deep-dive-into-deep-networks-math-17660bc376ba)
* [Quick Reference for Neural Networks & Keras](https://medium.com/@billypyu/quick-reference-neural-networks-keras-90341f556264)
* [A Friendly Introduction to Cross-Entropy Loss](https://rdipietro.github.io/friendly-intro-to-cross-entropy-loss/)
* [Intro to Neural Networks and Machine Learning](http://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/)
* [Top 10 Best Deep Learning Frameworks in 2019](https://towardsdatascience.com/top-10-best-deep-learning-frameworks-in-2019-5ccb90ea6de)
* [Beginner’s Guide to Object Detection Algorithms](https://towardsdatascience.com/beginners-guide-to-object-detection-algorithms-6620fb31c375)
* [The Basics of Recurrent Neural Networks (RNNs)](https://medium.com/towards-artificial-intelligence/whirlwind-tour-of-rnns-a11effb7808f)
* [Exploring Neural Networks with Activation Atlases](https://distill.pub/2019/activation-atlas/)
* [Auto-Encoder: What Is It? And What Is It Used For?](https://towardsdatascience.com/auto-encoder-what-is-it-and-what-is-it-used-for-part-1-3e5c6f017726)
* [37 Reasons why your Neural Network is not working](https://blog.slavv.com/37-reasons-why-your-neural-network-is-not-working-4020854bd607)
* [Everything you need to know about Neural Networks](https://hackernoon.com/everything-you-need-to-know-about-neural-networks-8988c3ee4491)
* [Attention and Augmented Recurrent Neural Networks](https://distill.pub/2016/augmented-rnns/)
* [Deep Neural Networks for YouTube Recommendations](https://static.googleusercontent.com/media/research.google.com/ru//pubs/archive/45530.pdf)
* [Calculus — Multivariate Calculus And Machine Learning](https://medium.com/fintechexplained/calculus-multivariate-calculus-and-machine-learning-242b9efcb41c)
* [Visualising Filters and Feature Maps for Deep Learning](https://towardsdatascience.com/visualising-filters-and-feature-maps-for-deep-learning-d814e13bd671)
* [An overview of gradient descent optimization algorithms](http://ruder.io/optimizing-gradient-descent/)
* [Advanced Topics in Deep Convolutional Neural Networks](https://towardsdatascience.com/advanced-topics-in-deep-convolutional-neural-networks-71ef1190522d)
* [Intuitively Understanding Convolutions for Deep Learning](https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1)
* [Diving deeper into Reinforcement Learning with Q-Learning](https://medium.freecodecamp.org/diving-deeper-into-reinforcement-learning-with-q-learning-c18d0db58efe)
* [Kaggle vs. Colab Faceoff — Which Free GPU Provider is Tops?](https://towardsdatascience.com/kaggle-vs-colab-faceoff-which-free-gpu-provider-is-tops-d4f0cd625029)
* [CS231n Convolutional Neural Networks for Visual Recognition](http://cs231n.github.io)
* [A Beginner's Guide To Understanding Convolutional Neural Networks](https://adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks-Part-2/)
* [Introduction to Convolutional Neural Networks (CNN) with TensorFlow](https://towardsdatascience.com/introduction-to-convolutional-neural-networks-cnn-with-tensorflow-57e2f4837e18)
* [Everything you need to know to master Convolutional Neural Networks](https://medium.freecodecamp.org/everything-you-need-to-know-to-master-convolutional-neural-networks-ef98ca3c7655)
* [Recurrent neural networks and LSTM tutorial in Python and TensorFlow](https://adventuresinmachinelearning.com/recurrent-neural-networks-lstm-tutorial-tensorflow/)
* [Machine learning fundamentals (I): Cost functions and gradient descent](https://towardsdatascience.com/machine-learning-fundamentals-via-linear-regression-41a5d11f5220)
* [Understanding Neural Networks: From Activation Function To Back Propagation](https://medium.com/fintechexplained/neural-networks-activation-function-to-back-propagation-understanding-neural-networks-bdd036c3f29f)
* [Deep Blue Sea: Using Deep Learning to Detect Hundreds of Different Plankton Species](https://towardsdatascience.com/deep-blue-sea-using-deep-learning-to-detect-hundreds-of-different-plankton-species-dff895d3b226)
* [Analyzing different types of activation functions in neural networks — which one to prefer?](https://towardsdatascience.com/analyzing-different-types-of-activation-functions-in-neural-networks-which-one-to-prefer-e11649256209)
* [Artificial Neural Network and it’s contribution to Machine Learning — A beginner’s hand-book](https://blog.goodaudience.com/artificial-neural-networks-and-its-contribution-to-machine-learning-a-beginner-s-hand-book-ab7f4e7b230e)
* [[Personal Notes] Deep Learning by Andrew Ng — Course 1: Neural Networks and Deep Learning](https://medium.com/@keonyonglee/bread-and-butter-from-deep-learning-by-andrew-ng-course-1-neural-networks-and-deep-learning-41563b8fc5d8)
* [The Secret Layer Behind Every Successful Deep Learning Model: Representation Learning and Knowledge Quality](https://towardsdatascience.com/the-secret-layer-behind-every-successful-deep-learning-model-representation-learning-and-knowledge-8f352018c561)

## Human Neural Network
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/HumanNeuralNetwork.png)

## Artificial Neural Network
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/GeneralLearningAlgorithm.png)

![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/ForwardAndBackwardPropagation.png)
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/NeuralNetwork_02.png)
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/NeuralNetwork_01.png)
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/ArtificialNeuralNetwork.png)
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/NeuralNetworkWeightsActivation.png)
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/Weights.png)
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/GradientDescent.png)
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/GlobalvsLocalMinimum.png)
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/LearningRate.png)
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/GradientClipping.png)

* __Perceptron__

![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/Perceptron.png)

* __Long Short-Term Memory (LSTM)__

![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/LongShortTermMemory.png)

* __Recurrent Neural Network__
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/RecurrentNeuralNetwork.png)

* __Convolutional Neural Network__
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/BasicCNN.png)
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/ConvolutionalNeuralNetwork_01.png)
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/ConvolutionalNeuralNetwork_02.png)

* __VGG16__

![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/VGG16.png)

* __Deep Generative Models__
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/TaxonomyOfDeepGenerativeModels.png)

## Neural Network Layers, Weights, and Bias
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/NeuralNetworkWeightsBias_01.png)
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/NeuralNetworkWeightsBias_02.png)
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/NeuralNetworkWeightsBias_03.png)
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/NeuralNetworkWeightsBias_04.png)
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/NeuralNetworkWeightsBias_05.png)
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/NeuralNetworkLayers_01.png)
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/NeuralNetworkLayers_02.png)
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/NeuralNetworkLayers_03.png)
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/NeuralNetworkLayers_04.png)
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/NeuralNetworkLayers_05.png)
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/NeuralNetworkLayers_06.png)
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/NeuralNetworkLayers_07.png)
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/NeuralNetworkLayers_08.png)

## Keras Lifecycle
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/Keras_Lifecycle.png)

## Entropy
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/Entropy.jpg)

## Batch Normalization
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/BatchNormalization.png)

![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/ActivationFunctions_01.png)
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/ActivationFunctions_02.png)

Activation functions play a key role in every neural network. They decide which nodes to fire in a particular layer. These functions are applied to hidden as well as to the output layers of a neural network.

Activation functions take the weighted sum of inputs plus a bias as input to the function (w(i)*x(i)+b) and perform the necessary computation to decide which nodes to fire in a layer.

There are many popular activation functions that play a significant role in building a neural network. Choosing the correct activation function depends on the kind of task you are performing.

* __Linear function__

![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/LinearFunction.png)

* __Step function__ - also known as a Threshold function. Here we set a threshold value and if the Y value(output) is greater than the threshold value, the function is activated and fired, else it is not fired.
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/StepFunction.png)

* __ReLU function__ - one of the most widely used activation functions. It stands for Rectified Linear Unit. It gives an output of X, if X is positive and 0 otherwise. ReLU is often used in the hidden layers.
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/ReLUFunction.png)

* __Sigmoid function__ - very common and is used to predict the probability as an output. The output of this function always lies between 0 and 1. Sigmoid is used in hidden layers as well as in the output layers where the target is binary.
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/SigmoidFunction.png)

* __Tanh function__ - similar to a Sigmoid function but is bound between the range (-1, 1). It is also used in the hidden layers as well as in the output layer.

![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/TanhFunction.png)

* __Softmax function__ - generally used in the output layer. It converts every output to been in the range of 0 and 1, just like the Sigmoid function. But it divides each output such that the total sum of the outputs is equal to 1.
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/SoftmaxFunction_01.png)
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/SoftmaxFunction_02.png)

## Transfer Learning
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/TransferLearning_Basic.png)
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/TransferLearning_01.png)
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/TransferLearning_02.png)
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/TransferLearning_03.png)
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/TransferLearning_04.png)

## Reinforcement Learning
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/ReinforcementLearning_01.png)
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/ReinforcementLearning_02.png)

## Autoencoder
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/Autoencoder_01.png)
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/Autoencoder_02.png)

## Model Tuning
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/AugmentedCat.png)
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/Dropout.png)
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/Overfitting.png)
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/EarlyStopping.png)
![](https://github.com/geoffreylink/Projects/blob/master/11%20Deep%20Learning/images/ParsimonyWins.png)
