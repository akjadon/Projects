{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t2.micro, AWS Marketplace -> Anaconda with Python 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n",
      "[[1. 1. 0. 0.]\n",
      " [1. 1. 0. 0.]\n",
      " [1. 1. 0. 0.]\n",
      " [1. 1. 0. 0.]\n",
      " [1. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "print(iris.data                                                    [0:5,:]    )\n",
    "print(np.around(Binarizer(threshold = 1.5).fit_transform(iris.data)[0:5,:], 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Data Rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n",
      "[[0.22 0.62 0.07 0.04]\n",
      " [0.17 0.42 0.07 0.04]\n",
      " [0.11 0.5  0.05 0.04]\n",
      " [0.08 0.46 0.08 0.04]\n",
      " [0.19 0.67 0.07 0.04]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "print(iris.data                                                            [0:5,:]   )\n",
    "print(np.around(MinMaxScaler(feature_range=(0, 1)).fit_transform(iris.data)[0:5,:],2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n",
      "[[-0.9   1.02 -1.34 -1.32]\n",
      " [-1.14 -0.13 -1.34 -1.32]\n",
      " [-1.39  0.33 -1.4  -1.32]\n",
      " [-1.51  0.1  -1.28 -1.32]\n",
      " [-1.02  1.25 -1.34 -1.32]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "print(iris.data                                          [0:5,:]    )\n",
    "print(np.around(StandardScaler().fit_transform(iris.data)[0:5,:], 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n",
      "[[0.8  0.55 0.22 0.03]\n",
      " [0.83 0.51 0.24 0.03]\n",
      " [0.81 0.55 0.22 0.03]\n",
      " [0.8  0.54 0.26 0.03]\n",
      " [0.79 0.57 0.22 0.03]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "print(iris.data                                      [0:5,:]    )\n",
    "print(np.around(Normalizer().fit_transform(iris.data)[0:5,:], 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1' 'this']\n",
      " ['2' 'is']\n",
      " ['3' 'how']\n",
      " ['4' 'we']\n",
      " ['5' 'encode']\n",
      " ['6' 'categorical']\n",
      " ['7' 'variables']\n",
      " ['8' 'variables']\n",
      " ['9' 'Variables']]\n",
      "[['1' '5']\n",
      " ['2' '4']\n",
      " ['3' '3']\n",
      " ['4' '7']\n",
      " ['5' '2']\n",
      " ['6' '1']\n",
      " ['7' '6']\n",
      " ['8' '6']\n",
      " ['9' '0']]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data = np.array([\n",
    "                 [1, \"this\"       ],\n",
    "                 [2, \"is\"         ],\n",
    "                 [3, \"how\"        ],\n",
    "                 [4, \"we\"         ],\n",
    "                 [5, \"encode\"     ],\n",
    "                 [6, \"categorical\"],\n",
    "                 [7, \"variables\"  ],\n",
    "                 [8, \"variables\"  ],\n",
    "                 [9, \"Variables\"  ],\n",
    "               ])\n",
    "\n",
    "print(data)\n",
    "data[:,-1] = LabelEncoder().fit_transform(data[:,-1])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rent  city_NYC  city_SF  city_Seattle\n",
      "0  3999         0        1             0\n",
      "1  4000         0        1             0\n",
      "2  4001         0        1             0\n",
      "3  3499         1        0             0\n",
      "4  3500         1        0             0\n",
      "5  3501         1        0             0\n",
      "6  2499         0        0             1\n",
      "7  2500         0        0             1\n",
      "8  2501         0        0             1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "                   'City': ['SF', 'SF', 'SF', 'NYC', 'NYC', 'NYC', 'Seattle', 'Seattle', 'Seattle'], \n",
    "                   'Rent': [3999, 4000, 4001,  3499,  3500,  3501,      2499,      2500,     2501 ]\n",
    "                 })\n",
    "\n",
    "print(pd.get_dummies(df, prefix=['city']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
