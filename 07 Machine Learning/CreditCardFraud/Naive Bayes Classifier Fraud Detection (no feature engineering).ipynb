{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Naive Bayes Classifier Fraud Detection using a highly unbalanced dataset from Kaggle</b><br>\n",
    "No feature engineering allowing for a concise notebook illustrating Hyperparameter Tuning & Training with AWS Sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/mlg-ulb/creditcardfraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Python Modules\n",
    "\n",
    "import os\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sagemaker import s3_input\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.sklearn.model import SKLearnPredictor\n",
    "from sagemaker.tuner import HyperparameterTuner\n",
    "from sagemaker.tuner import ContinuousParameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Unique Variables\n",
    "\n",
    "role             = 'AmazonSageMaker-ExecutionRole-20191005T164168'\n",
    "prefix           = 'naivebayesclassifier'\n",
    "bucket           = 'creditcardfraud123'\n",
    "csv_filename     = 's3://' + bucket + '/creditcard.csv'\n",
    "endpoint_name    = 'creditcardnaivebayesclassifier'\n",
    "sagemaker_client = boto3.Session().client('sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly Separate Train, Validation, and Test Datasets\n",
    "\n",
    "df = pd.read_csv(csv_filename)\n",
    "\n",
    "model_data = df[df.columns.tolist()[-1:] + df.columns.tolist()[:-1]]\n",
    "\n",
    "train_data, validation_data, test_data = np.split(\n",
    "                                                  model_data.sample(frac=1),\n",
    "                                                  [\n",
    "                                                   int(0.7 * len(model_data)),\n",
    "                                                   int(0.9 * len(model_data))\n",
    "                                                  ]\n",
    "                                                 )\n",
    "\n",
    "train_data.to_csv(     'train.csv'     , header=True, index=False)\n",
    "validation_data.to_csv('validation.csv', header=True, index=False)\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train/train.csv'          )).upload_file('train.csv'     )\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'validation/validation.csv')).upload_file('validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Fraud Count in Train Set = 284315.0\n",
      "Fraud Count in Train Set     = 492.0\n",
      "Class Weight Scale Factor    = 577.9\n"
     ]
    }
   ],
   "source": [
    "# Define Class Weights for Highly Unbalanced Fraud Data\n",
    "\n",
    "class_counts  = df['Class'].reset_index().groupby('Class').agg('count').values\n",
    "class_weights = float(class_counts[0]/float(class_counts[1]))\n",
    "\n",
    "print('Non-Fraud Count in Train Set = {}'.format(    float(class_counts[0])))\n",
    "print('Fraud Count in Train Set     = {}'.format(    float(class_counts[1])))\n",
    "print('Class Weight Scale Factor    = {:.1f}'.format(class_weights         ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script.py\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    return joblib.load('/opt/ml/model/model.joblib')\n",
    "\n",
    "if __name__ =='__main__':\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--features', type=str)\n",
    "    parser.add_argument('--target'  , type=str)\n",
    "\n",
    "    parser.add_argument('--var_smoothing', type=float)\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    train_df = pd.read_csv('/opt/ml/input/data/train/train.csv'    )\n",
    "    test_df  = pd.read_csv('/opt/ml/input/data/test/validation.csv')\n",
    "\n",
    "    X_train = train_df[args.features.split()]\n",
    "    y_train = train_df[args.target          ]\n",
    "    X_test  = test_df[ args.features.split()]\n",
    "    y_test  = test_df[ args.target          ]\n",
    "\n",
    "    model = GaussianNB(\n",
    "                       var_smoothing = args.var_smoothing\n",
    "                      ).fit(\n",
    "                            X_train,\n",
    "                            y_train\n",
    "                           )\n",
    "\n",
    "    joblib.dump(\n",
    "                model                       ,\n",
    "                '/opt/ml/model/model.joblib'\n",
    "               )\n",
    "\n",
    "    for q in [10, 50, 90]:\n",
    "        print('AE-at-' + str(q) + 'th-percentile: ' + str(np.percentile(a=np.abs(model.predict(X_test) - y_test), q=q)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Launch Training and HyperParameter Tuning Jobs using Spot Instances\n",
    "\n",
    "rfc = SKLearn(\n",
    "              entry_point              = 'script.py'         ,\n",
    "              role                     = get_execution_role(),\n",
    "              train_instance_count     = 1                   ,\n",
    "              train_instance_type      = 'ml.m5.large'       ,\n",
    "              train_use_spot_instances = True                ,\n",
    "              train_max_run            = 3600                ,\n",
    "              train_max_wait           = 3600                ,\n",
    "              metric_definitions       = [{\n",
    "                                           'Name'  : 'median-AE'                          ,\n",
    "                                           'Regex' : \"AE-at-50th-percentile: ([0-9.]+).*$\"\n",
    "                                         }]                  ,\n",
    "              hyperparameters          = {\n",
    "                                          'var_smoothing' : 1e-9                                                                                                           ,\n",
    "                                          'features' : 'Time V1 V2 V3 V4 V5 V6 V7 V8 V9 V10 V11 V12 V13 V14 V15 V16 V17 V18 V19 V20 V21 V22 V23 V24 V25 V26 V27 V28 Amount',\n",
    "                                          'target'   : 'Class'\n",
    "                                         }\n",
    "             )\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "                            estimator             = rfc              ,\n",
    "                            max_jobs              = 3                ,\n",
    "                            max_parallel_jobs     = 2                ,\n",
    "                            hyperparameter_ranges = {\n",
    "                                                     'var_smoothing' : ContinuousParameter(1e-9, 1e-8)\n",
    "                                                    }                ,\n",
    "                            objective_type        = 'Minimize'       ,\n",
    "                            objective_metric_name = 'median-AE'      ,\n",
    "                            metric_definitions    = [{\n",
    "                                                      'Name'  : 'median-AE'                          ,\n",
    "                                                      'Regex' : 'AE-at-50th-percentile: ([0-9.]+).*$'\n",
    "                                                    }]\n",
    "                           )\n",
    "\n",
    "tuner.fit({\n",
    "           'train' : s3_input(s3_data='s3://{}/{}/train/'.format(     bucket, prefix), content_type='text/csv'),\n",
    "           'test'  : s3_input(s3_data='s3://{}/{}/validation/'.format(bucket, prefix), content_type='text/csv')\n",
    "         })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------! \n",
      "Accuracy  = 99.8\n",
      "Precision = 28.9\n",
      "Recall    = 27.7\n",
      "F1 Score  = 28.3\n"
     ]
    }
   ],
   "source": [
    "# Create Ephemeral Endpoint to Analyze Best Tuned Model\n",
    "\n",
    "if sagemaker_client.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName=tuner.latest_tuning_job.name)['HyperParameterTuningJobStatus'] == 'Completed':\n",
    "    \n",
    "    best_training_job = sagemaker_client.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName=tuner.latest_tuning_job.name)['BestTrainingJob']['TrainingJobName']\n",
    "\n",
    "    SKLearnModel(\n",
    "                 model_data  = sagemaker_client.describe_training_job(TrainingJobName=best_training_job)['ModelArtifacts']['S3ModelArtifacts'],\n",
    "                 role        = get_execution_role()                                                                                           ,\n",
    "                 entry_point = 'script.py'\n",
    "                ).deploy(\n",
    "                         initial_instance_count = 1              ,\n",
    "                         instance_type          = 'ml.t2.2xlarge',\n",
    "                         endpoint_name          = endpoint_name\n",
    "                        )\n",
    "\n",
    "    predictor = SKLearnPredictor(endpoint_name)\n",
    "\n",
    "    true_positive  = 0\n",
    "    false_positive = 0\n",
    "    true_negative  = 0\n",
    "    false_negative = 0\n",
    "\n",
    "    columns = ['Time','V1','V2','V3','V4','V5','V6','V7','V8','V9','V10','V11','V12','V13','V14','V15','V16','V17','V18','V19','V20','V21','V22','V23','V24','V25','V26','V27','V28','Amount']\n",
    "    \n",
    "    for i in range(0, test_data.count()['Class']):\n",
    "        \n",
    "        prediction = predictor.predict(test_data.iloc[i:i+1][columns])[0]\n",
    "        \n",
    "        if prediction > 0:\n",
    "\n",
    "            if int(test_data.iloc[i:i+1]['Class']) == prediction:\n",
    "                true_positive  += 1\n",
    "            else:\n",
    "                false_positive += 1\n",
    "\n",
    "        else:\n",
    "\n",
    "            if int(test_data.iloc[i:i+1]['Class']) == prediction:\n",
    "                true_negative  += 1\n",
    "            else:\n",
    "                false_negative += 1\n",
    "\n",
    "    predictor.delete_endpoint()\n",
    "    predictor.delete_model()\n",
    "\n",
    "    print(' ')\n",
    "    if true_positive+true_negative+false_positive+false_negative > 0:     print('Accuracy  = {:.1f}'.format(((true_positive+true_negative)/(true_positive+true_negative+false_positive+false_negative))*100))\n",
    "    if true_positive+false_positive > 0:                                  print('Precision = {:.1f}'.format((true_positive/(true_positive+false_positive))*100))\n",
    "    if true_positive+false_negative > 0:                                  print('Recall    = {:.1f}'.format((true_positive/(true_positive+false_negative))*100))\n",
    "    if true_positive+false_positive and true_positive+false_negative > 0: print('F1 Score  = {:.1f}'.format((2*((true_positive/(true_positive+false_positive))*(true_positive/(true_positive+false_negative)))/((true_positive/(true_positive+false_positive))+(true_positive/(true_positive+false_negative))))*100))\n",
    "\n",
    "else:\n",
    "\n",
    "    print('Please wait for tuning job to complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
